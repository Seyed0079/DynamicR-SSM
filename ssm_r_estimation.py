# -*- coding: utf-8 -*-
"""ssm_R_estimation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FkhCDTzO4BWPiWYu43Z__0rGADzNUEtC
"""

# Commented out IPython magic to ensure Python compatibility.
#imports
# %matplotlib inline
import numpy as np
import math
import time
import matplotlib.pyplot as plt
from scipy.special import erfc, gammaln
from scipy.stats import poisson
import pandas as pd

# helper functions

def P_vec(t, pk):
    t = np.asarray(t)
    out = np.zeros_like(t, dtype=float)
    mask = t > 0
    if np.any(mask):
        out[mask] = 0.5 * erfc(-(np.log(t[mask]) - pk["mu"]) / math.sqrt(2 * pk["sg2"]))
    return out

def knl_vec(t, pk):
    # knl(k) = P(k) - P(k-1)
    t = np.asarray(t)
    return P_vec(t, pk) - P_vec(t - 1, pk)

def rhoest(n, l=7):
    x = np.nan_to_num(n, nan=0.0)
    mn = np.convolve(x, np.ones(l)/l, mode='same')
    mask = mn != 0
    if np.any(mask):
        rho = np.mean((x[mask] - mn[mask])**2 / mn[mask]) - 1.0
    else:
        rho = 0.0
    return max(rho, 0.0)

def cauchyrnd(x0, gm, m, n):
    return x0 + gm * np.tan(np.pi*(np.random.rand(m, n) - 0.5))

def ramp(x):
    x = np.array(x, copy=True)
    x[x < np.finfo(float).eps] = np.finfo(float).eps
    return x

def nbinom_pmf_scalar_k(k, r, p):
    """
    Negative-binomial pmf for integer k, shape r (can be array) and prob p.
    PMF = Gamma(k+r)/(Gamma(k+1)Gamma(r)) * p^r * (1-p)^k
    Handles r==0 as degenerate case (P(k==0)=1).
    """
    r = np.asarray(r)
    pmf = np.zeros_like(r, dtype=float)
    # positive r
    pos = r > 0
    if np.any(pos):
        rp = r[pos]
        with np.errstate(divide='ignore', invalid='ignore'):
            logpmf = gammaln(k + rp) - gammaln(k + 1) - gammaln(rp) + rp * np.log(p) + k * np.log(1.0 - p)
            pmf[pos] = np.exp(logpmf)
    # r == 0
    zero_mask = (r == 0)
    if np.any(zero_mask):
        pmf[zero_mask] = 1.0 if k == 0 else 0.0
    pmf = np.where(np.isfinite(pmf), pmf, 0.0)
    return pmf

# main function (optimized)
def rnssest_python(n, N=10**4, gm=1e-2, d=30, L=30, verbose=False, random_seed=None):
    """
    Returns dict: { 'R': array(len=T-1), 'itvl': array(2, T-1), 'rate': array(len=T) }
    """
    if random_seed is not None:
        np.random.seed(random_seed)
    n = np.asarray(n, dtype=float).flatten()
    T = n.size
    I = np.isnan(n)
    n[I] = 0.0
    mu = np.finfo(float).eps
    rho = rhoest(n, 7)
    if verbose:
        print(f"rho estimate = {rho:.6f}")

    # kernel parameters
    m_val, sd = 4.7, 2.9
    pk = {"mu": math.log(m_val / math.sqrt(1 + (sd/m_val)**2)), "sg2": math.log(1 + (sd/m_val)**2)}

    # precompute kernels
    knl_d = knl_vec(np.arange(1, d+1), pk)    # length d (for lm)
    knl_full = knl_vec(np.arange(1, T+1), pk) # length T (for rate)

    # initialize particles
    sx = np.zeros((d, int(N), int(L)), dtype=np.float32)
    px = (np.random.rand(d, int(N)).astype(np.float32) * 10.0)

    R_list = []
    itvl_list = []

    start_time = time.time()
    for t in range(T):
        sx[:, :, -1] = px
        if not I[t]:
            # prepare n0: [n[t-1], n[t-2], ..., n[t-d]] padded with zeros
            if t == 0:
                n0 = np.zeros(d, dtype=float)
            else:
                start = max(0, t - d)
                arr = n[start:t][::-1]
                n0 = np.zeros(d, dtype=float)
                n0[:arr.size] = arr
            coef = (n0 * knl_d).astype(np.float32)
            # lm per particle
            lm = mu + coef @ px   # shape (N,)
            if rho > 0:
                r = lm / rho
                p_nb = 1.0 / (rho + 1.0)
                w = nbinom_pmf_scalar_k(int(n[t]), r, p_nb)
            else:
                w = poisson.pmf(int(n[t]), lm)
            w = np.where(np.isfinite(w), w, 0.0)
            sw = w.sum()
            if sw > 0 and np.any(w > 0):
                p_w = w / sw
                # resample indices (multinomial)
                newp = np.random.choice(px.shape[1], size=px.shape[1], p=p_w)
                sx = sx[:, newp, :]

        # record median and quantiles from earliest slice (smoothing buffer)
        s0 = sx[0, :, 0]
        R_list.append(float(np.median(s0)))
        itvl_list.append(np.quantile(s0, [0.025, 0.975]).astype(float))

        # propagate state: optimized F * x (shift)
        x_last = sx[:, :, -1]
        fx = np.empty_like(x_last)
        fx[0, :] = x_last[0, :]
        fx[1:, :] = x_last[:-1, :]
        noise = cauchyrnd(0.0, gm, 1, px.shape[1]).astype(np.float32)
        gnoise = np.zeros_like(fx); gnoise[0, :] = noise[0, :]
        px = ramp(fx + gnoise)

        sx[:, :, :-1] = sx[:, :, 1:]  # shift buffer left

        if verbose and ((t+1) % 200 == 0 or t == T-1):
            print(f"t={t+1}/{T}, elapsed={(time.time()-start_time):.1f}s")

    # smoothing tail
    for tt in range(L-1):
        s_t = sx[0, :, tt]
        R_list.append(float(np.median(s_t)))
        itvl_list.append(np.quantile(s_t, [0.025, 0.975]).astype(float))

    R_arr = np.array(R_list, dtype=float)       # length T + L - 1
    itvl_arr = np.array(itvl_list, dtype=float)  # shape (T+L-1, 2)

    # drop first L entries (MATLAB: R = R(L+1:end))
    if R_arr.size <= L:
        raise ValueError("Not enough elements after smoothing to drop L samples.")
    R_final = R_arr[L:]
    itvl_final = itvl_arr[L:].T   # shape (2, T-1)

    # compute rate
    rate = np.zeros(T, dtype=float)
    for t in range(T):
        if t == 0:
            rate[t] = mu
        else:
            a = R_final[:t] * n[:t]
            b = knl_full[t-1::-1][:t]
            rate[t] = mu + float(np.dot(a, b))

    return {"R": R_final, "itvl": itvl_final, "rate": rate}

#(paste original data here)
n = np.array([
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,13,10,15,20,32,44,106,143,
205,385,523,835,586,591,1234,1076,743,595,881,958,1075,1289,1365,1209,1053,1178,1192,1046,1237,966,1028,1411,1762,2206,2389,2926,
3076,2901,3186,3111,2987,2875,2715,2560,2483,2274,2089,1997,1634,1972,1837,1657,1617,1574,1512,1606,1499,1374,1343,1294,1297,1194,
1030,1168,1134,1153,991,1112,1073,983,1006,802,976,1223,1323,1680,1485,1556,1529,1383,1683,1481,1958,1808,2102,1757,1806,2294,2111,
2346,2392,2311,1869,2180,2023,1787,2080,2258,2819,2282,2516,2979,3117,3134,3574,2886,2269,2364,2043,2095,2011,2238,2369,2410,2472,
2449,2563,2612,2596,2615,2322,2368,2573,2445,2531,2595,2628,2456,2489,2536,2457,2549,2652,2566,2449,2560,2613,2637,2691,2079,2262,
2397,2186,2349,2521,2388,2500,2379,2166,2182,2414,2625,2586,2621,2489,2316,2333,2434,2667,2636,2621,2674,2548,2685,2598,2751,2697,
2634,2450,2125,2020,2132,2345,2510,2625,2501,2245,2133,2247,2385,2444,2279,2206,2028,2113,2245,2213,2243,2190,2115,1905,1754,1642,
1682,1858,1994,2026,1894,1992,2152,2302,2313,2063,2313,2139,2089,2619,2705,2981,2815,3049,2845,3097,3341,3712,3605,3521,3563,3204,
3362,3512,3677,3582,3825,3552,3523,3653,3902,4151,4019,4392,4142,3875,3822,4206,4108,4830,4616,4552,4103,3890,4251,5039,5616,5471,
6134,5814,6191,5960,6968,6824,8293,8011,7820,7719,8289,8932,8452,8772,8864,9450,9236,10463,10339,11780,11517,11737,11203,12543,13053,
13352,13421,13223,13260,12931,13053,12460,13721,13843,13961,14051,13402,12950,13321,13881,13621,13922,13341,12151,11561,10827,11023,
10223,10403,9594,8201,7451,7501,7704,7603,7453,7121,6421,6312,6151,6208,6261,6178,6021,5760,5502,5908,6108,6272,6390,6286,6045,5960,
6073,6113,6283,6360,6251,5924,5968,6208,6408,6317,6471,6485,6100,6016,5806,5917,6182,6204,6305,6207,5945,6309,6420,6608,6527,6573,6317,
6268,6597,6820,6870,7040,7061,6983,7065,7321,7640,7585,7474,7298,7120,7390,7760,8011,8042,8066,8017,7922,7931,8263,8330,8270,8206,8103,
7975,8010,8510,8495,8525,8404,8367,8212,8010,8313,8554,8603,8308,8088,7802,7593,7980,8380,7802,7530,7620,7540,7260,7357,7290,7605,7506,
7980,8120,8751,9310,10250,10330,11750,11660,11420,11680,13890,17430,20954,22586,22478,19666,21063,23311,24760,25582,25078,25261,21312,
21644,24346,25492,24886,24092,22904,18230,19165,21026,20963,21713,19899,19272,17080,18698,20732,20150,15872,18409,17076,13576,14141,18408,
18133,16409,14246,10145,7723,11291,14319,13930,12789,12428,11250,8005,8631,11005,11873,10468,9994,10253,7107,8876,11042,10687,11620,9657,
9209,6442,5612,4907,8846,10598,12398,9966,7444,8195,10715,10216,10487,10291,10100,6448,8161,10485,11716,11059,11734,10820,7034,9758,12351,
12717,11748,14303,13836,8341,13781,16025,16080,17212,23391,16596,11664,17664,20829,22750,23371,23655,21885,15139,22184,25441,27444,27379,
20313,21814,18632,27146,31814,34951,33817,34433,24715,19846,32511,37189,39019,39357,38674,34913,26439,39619,40808,39139,42541,39049,39119,
29700,36736,41194,50228,39174,31266,28833,24179,36419,38657,40623,39983,36758,36279,26034,31516,33780,31319,33170,30279,27621,20404,25870,
27579,27138,26854,26821,21114,16654,20219,22541,22329,19731,18021,17605,12847,15975,17397,17564,17433,16362,15294,10843,13792,14470,11701,
13271,14078,14525,10135,12428,14607,13226,10497,11625,9897,7654,11256,13504,13391,12298,11964,11857,7515,11396,11844,13308,11770,11788,11064,
7081,9174,7516,9096,10644,11409,9893,6809,8427,9857,10104,10363,9862,8633,6803,7554,8341,8305,7948,7539,7322,4306,6143,7494,6430,6251,5882,
5784,3539,4340,5427,5144,4813,4850,4384,3045,3781,4310,4253,4312,3839,3603,2157,3109,3356,3514,3309,3228,2971,1681,2289,2706,2784,2651,2500,
2196,1361,1968,2390,2413,2103,1932,1967,1121,1857,1967,2128,1905,1936,1703,1002,1510,1677,1706,1171,1171,1178,701,1480,2340,1961,2089,2394,
2539,1421,2292,3163,3653,4060,4658,5276,3503,5144,7691,9378,11851,14285,16757,11731,21996,28995,35070,38160,37395,36908,23130,35429,39819,
38757,39085,33681,31247,18598,25812,28956,25034,16310,17545,19317,12058,16967,19110,22073,15340,12957,11972,7039,9524,10962,9312,6234,6772,
6470,4089,5586,6426,5841,5008,6424,3953,2219,3330,3813,3223,3010,2580,2175,1323,1816,1256,1120,1123,1345,1530,1382,2299,2915,2743,2987,2487,
2264,1887,1275,3519,4615,4228,3800,3184,1757,2894,3125,2737,2356,2194,1994,1015,1895,2009,1820,1607,1413,1096,608,528,1077,1307,1009,969,719,
532,655,697,571,252,228,375,270,488,570,460,453,371,385,255,368,383,352,288,280,228,159,312,268,268,293,217,185,103,175,240,232,234,175,171,
64,53,59,139,188,202,153,56,160,192,162,179,146,156,74,160,231,187,265,256,232,136,297,352,443,441,529,463,251,717,1007,1084,1271,1775,2013,
894,2375,1453,3588,5000,5234,4772,2704,5751,5687,5377,7093,7915,7851,6921,8831,9775,11035,10526,9456,7849,4505,9727,9699,9350,8540,7415,5455,
3460,5477,3379,2343,5635,7396,6404,3315,6279,7348,5972,4824,4527,3690,1835,3245,4088,3227,2667,2378,0,2995,1693,1966,1871,1462,1364,0,1599,
1163,1095,1090,945,864,700,344,696,877,618,646,624,644,303,289,726,992,811,504,421,397,416,308,309,262,352,0,866,400,435,380,290,165,0,501,
323,724,408,357,285,155,397,327,370,307,345,200,139,209,194,535,222,170,110,106,124,73,213,155,115,42,40,76,64,360,91,97,72,50,81,57,51,54,
74,35,47,47,38,72,48,30,21,25,34,63,45,30,42,31,23,39,56,69,34,41,49,19,38,57,55,30,47,29,0,66,55,75,62,48,38,0,64,61,60,35,60,51,60
], dtype=float)
print("T =", n.size)

#run experiments (N=1e3 and N=1e4)
results = {}
for N in (1000, 10000, 100000, 1000000):
    print(f"\nRunning rnssest with N={N} ... (this can take a while)")
    t0 = time.time()
    out = rnssest_python(n, N=int(N), gm=1e-2, d=30, L=30, verbose=True, random_seed=123)
    dt = time.time() - t0
    print(f"Done N={N} in {dt:.1f}s. R length = {out['R'].size}, rate length = {out['rate'].size}")
    results[N] = out
    # save CSV
    dfR = pd.DataFrame({
        "R": out["R"],
        "itvl_low": out["itvl"][0,:],
        "itvl_high": out["itvl"][1,:]
    })
    dfR.to_csv(f"R_itvl_N{N}.csv", index=False)
    pd.DataFrame({"rate": out["rate"]}).to_csv(f"rate_N{N}.csv", index=False)
    print(f"Saved R_itvl_N{N}.csv and rate_N{N}.csv")

#plotting helper and show results
def plot_results(n, out, title=""):
    T = n.size
    tt = np.arange(1, T+1)
    fig, axs = plt.subplots(2,1, figsize=(12,8))
    axs[0].plot(tt, n, label="Original data")
    axs[0].plot(tt, out["rate"], label="estimated rate")
    axs[0].set_ylabel("n_i")
    axs[0].legend()
    xR = np.arange(1, T)
    axs[1].fill_between(xR, out["itvl"][0,:], out["itvl"][1,:], alpha=0.25, label="95% interval")
    axs[1].plot(xR, out["R"], label="R (median)")
    axs[1].axhline(1.0, color='k', linestyle=':', linewidth=1)
    axs[1].set_ylabel("Reproduction number")
    axs[1].legend()
    axs[0].set_title(title)
    plt.tight_layout()
    plt.show()

# show plots for runs that finished
for N, out in results.items():
    plot_results(n, out, title=f"rnssest results (N={N})")

from google.colab import files
files.download("R_itvl_N1000.csv")
files.download("rate_N1000.csv")
files.download("R_itvl_N10000.csv")
files.download("rate_N10000.csv")
files.download("R_itvl_N100000.csv")
files.download("rate_N100000.csv")
files.download("R_itvl_N1000000.csv")
files.download("rate_N1000000.csv")

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from IPython.display import Image, display

def simulate_R_estimation(n, N, gm=0.001):
    """
    Simulates R estimation (dummy version, since real rnssest is MATLAB code).
    Generates R, confidence interval, and rate vectors with slight length differences.
    """
    T = len(n)
    # Smooth version of n
    rate = np.convolve(n, np.ones(7)/7, mode="same")
    # R values (length T-1 or sometimes shorter)
    R = rate[1:] / (rate[:-1] + 1e-6)
    # Add random noise
    R = np.maximum(R + np.random.normal(0, 0.1, size=len(R)), 0.01)
    # Confidence interval
    itvl = np.vstack([R * 0.9, R * 1.1])
    return {"R": R, "itvl": itvl, "rate": rate}

# Example synthetic epidemic data (replace with your real n)
np.random.seed(42)
n = np.random.poisson(lam=50, size=1097)

Ns = [1000, 10000, 100000, 1000000]
loaded = {}

for N in Ns:
    loaded[f"N{N}"] = simulate_R_estimation(n, N)

print("Simulations finished for N =", Ns)

summary_rows = []
for tag, out in loaded.items():
    R = out["R"]
    rate = out["rate"]
    row = {
        "tag": tag,
        "mean_R": np.mean(R),
        "median_R": np.median(R),
        "last_R": R[-1],
        "prop_R_gt1": np.mean(R > 1) * 100,
        "mean_rate": np.mean(rate),
        "median_rate": np.median(rate),
        "n_days": len(R),
    }
    summary_rows.append(row)

df_summary = pd.DataFrame(summary_rows)
df_summary.to_csv("summary_R_stats.csv", index=False)
df_summary

def plot_rate_and_R_robust(n, out, tag="N"):
    n = np.asarray(n, dtype=float)
    R = np.asarray(out["R"], dtype=float)
    itvl = np.asarray(out["itvl"], dtype=float)
    rate = np.asarray(out["rate"], dtype=float)

    ln = len(n)
    lr = len(rate)
    lR = len(R)
    print(f"[{tag}] lengths -> n: {ln}, rate: {lr}, R: {lR}, itvl shape: {itvl.shape}")

    # Fix itvl shape
    if itvl.shape[1] != lR:
        min_len = min(itvl.shape[1], lR)
        itvl = itvl[:, :min_len]
        R = R[:min_len]
        lR = len(R)

    # Common length for n and rate
    L_common = min(ln, lr)
    tt = np.arange(1, L_common + 1)
    n_plot = n[:L_common]
    rate_plot = rate[:L_common]

    # Offset for R relative to rate
    offset = lr - lR
    tt_R = np.arange(1 + offset, 1 + offset + lR)

    mask_R = (tt_R >= 1) & (tt_R <= L_common)
    tt_R_plot = tt_R[mask_R]
    R_plot = R[mask_R]
    itvl_plot = itvl[:, mask_R]

    # Plot
    fig, axs = plt.subplots(2, 1, figsize=(12, 8))
    axs[0].plot(tt, n_plot, label="Daily cases (n)", lw=1.5, color="tab:green")
    axs[0].plot(tt, rate_plot, label="Estimated rate", lw=1.5, color="tab:blue")
    axs[0].set_xlim(1, L_common)
    axs[0].set_ylabel("Cases")
    axs[0].legend()
    axs[0].set_title(f"Data and Estimated Rate â€” {tag}")

    axs[1].fill_between(tt_R_plot, itvl_plot[0, :], itvl_plot[1, :],
                        color="lightblue", alpha=0.4, step=None, label="95% Range")
    axs[1].plot(tt_R_plot, R_plot, lw=1.5, label="R (median)", color="tab:blue")
    axs[1].axhline(1.0, color="k", linestyle="--", linewidth=1)
    axs[1].set_xlim(1, L_common)
    axs[1].set_ylabel("Effective reproduction number R")
    axs[1].legend()
    plt.tight_layout()

    fname = f"plot_{tag}_robust.png"
    fig.savefig(fname, dpi=150)
    plt.close(fig)
    print(f"[{tag}] saved: {fname}")
    return fname

saved_images = []
for tag, out in loaded.items():
    fname = plot_rate_and_R_robust(n, out, tag)
    saved_images.append(fname)
    display(Image(fname))

print("Done. Images saved:", saved_images)